given an array defined as:<br><br>arr = np.arange(30).reshape(5,6)<br><br>where arr looks like:<br><br>array([[ 0,  1,  2,  3,  4,  5],<br>       [ 6,  7,  8,  9, 10, 11],<br>       [12, 13, 14, 15, 16, 17],<br>       [18, 19, 20, 21, 22, 23],<br>       [24, 25, 26, 27, 28, 29]])<br><br>how could we select every 3rd element of the 3rd column?<br>what would the result yield?<br><br><br>	arr[::3, 2]<br>array([ 2, 20])<br><br>NOTE: Typical ndarray slicing looks like arr[3,:] for selecting the 4th row, and arr[:,3] for selecting the 4th column; the :: syntax allows you to do "every other" element for the specific dimension.
given an array defined as:<br><br>arr = np.arange(60).reshape(3,4,5)<br><br>where arr looks like:<br><br>array([[[ 0,  1,  2,  3,  4],<br>        [ 5,  6,  7,  8,  9],<br>        [10, 11, 12, 13, 14],<br>        [15, 16, 17, 18, 19]],<br><br>       [[20, 21, 22, 23, 24],<br>        [25, 26, 27, 28, 29],<br>        [30, 31, 32, 33, 34],<br>        [35, 36, 37, 38, 39]],<br><br>       [[40, 41, 42, 43, 44],<br>        [45, 46, 47, 48, 49],<br>        [50, 51, 52, 53, 54],<br>        [55, 56, 57, 58, 59]]])<br><br>how would you use an Ellipsis object to do the equivalent of arr[:,:,3]?<br>what would you expect the result to look like?	arr[...,3]<br>array([[ 3,  8, 13, 18],<br>       [23, 28, 33, 38],<br>       [43, 48, 53, 58]])<br><br>NOTE: an Ellipsis object expands to zero or more full slice objects (":") so the total number of dimensions of the slicing tuple matches the number of dimensions in the array. So here, arr.shape==(3,4,5), thus arr[...,3] is equivalent to arr[:,:,3]. Additionally, arr[0,...] is equivalent to arr[0,:,:], producing:<br><br>array([[ 0,  1,  2,  3,  4],<br>       [ 5,  6,  7,  8,  9],<br>       [10, 11, 12, 13, 14],<br>       [15, 16, 17, 18, 19]])
if we have a 4x3 C-contiguous array (arr.shape==(4,3)), and we slice such as arr[1:3,1:3], we have a sub-array which is neither C-contiguous nor Fortran-contiguous; yet, a regular indexing expression on an ndarray can always produce an ndarray object without copying any data, why?	the same striding tuple as the original array can be used to represent the sub-array as an ndarray object, often referred to as the "view" feature of array indexing.<br><br>NOTE: the benefit of enabling the "view" feature by the use of the original array's striding information is rapid indexing without exploding memory usage. As to striding, we can see strides from the .strides attribute; e.g. if arr.shape==(3,4,5) and arr.dtype=='int64', then arr.strides==(160, 40, 8) for a C-contiguous array. What this means is that it takes 160 / 8 = 20 jumps over elements to increment the first dimension by 1, which makes sense because the second and third dimensions are 4 and 5, and these need to be incremented first in a C-style array.
given a C-style array of shape 4 x 5 x 6 (e.g. arr.shape==(4,5,6)), how many elements must one jump over to increment the first index by one?	30; the second and third indices must be fully incremented first before starting over, hence there are 5 x 6 = 30 elements until the first index increase by one<br><br>NOTES: To determine the one-dimensional index corresponding to some element of a C-style array, we can use the following formula:<br><br>Let n_i be the value of the ith index into an array<br>Let N integers d_i represent the shape of the array<br>index = sum_(i=0 -> N-1) (n_i * mult_(j=i+1 -> N-1) (d_j))<br><br>e.g. we want element (1,3,2) of arr.shape==(4,5,6)<br>index = 1*(5*6) + 3*(6) + 2*(1) = 50
broadcasting allows ufuncs to deal in a meaningful way with inputs that do not have exactly the same shape, by applying two rules: the first rule of broadcasting is if all input arrays do not have the same number of dimensions, then a "1" will be repeatedly prepended to the shapes of the smaller arrays, until all arrays have the same number of dimensions; what is the second rule?	the second rule of broadcasting is arrays with a size of 1 along a particular dimension act as if they had the size of the array with the largest shape along this dimension, and the value of an array element is treated as being replicated along this dimension for the "broadcasted" array.<br><br>NOTES: 2nd rule illustration: suppose there is a ufunc with two inputs, A and B. Suppose A has shape 4 x 6 x 5 while B has shape 4 x 6 x 1. The ufunc will proceed to compute the 4 x 6 x 5 output as if B had been 4 x 6 x 5 by assuming B[..., k] = B[..., 0] for k = 1,2,3,4.<br><br>NOTES: 1st rule illustration: suppose there is a ufunc with two inputs, A and B. Suppose A has shape 4 x 6 x 5 while B is a length 5 array. Due to the 1st rule, B will be interpreted as a 1 x 1 x 5 array, and then because of the second rule B will be interpreted as a 4 x 6 x 5 array by repeating the elements of B in the obvious way.
broadcasting allows ufuncs to deal in a meaningful way with inputs that do not have exactly the same shape, by applying two rules: the second rule of broadcasting is arrays with a size of 1 along a particular dimension act as if they had the size of the array with the largest shape along this dimension, and the value of an array element is treated as being replicated along this dimension for the "broadcasted" array; what is the first rule?	the first rule of broadcasting is if all input arrays do not have the same number of dimensions, then a "1" will be repeatedly prepended to the shapes of the smaller arrays, until all arrays have the same number of dimensions.<br><br>NOTES: 2nd rule illustration: suppose there is a ufunc with two inputs, A and B. Suppose A has shape 4 x 6 x 5 while B has shape 4 x 6 x 1. The ufunc will proceed to compute the 4 x 6 x 5 output as if B had been 4 x 6 x 5 by assuming B[..., k] = B[..., 0] for k = 1,2,3,4.<br><br>NOTES: 1st rule illustration: suppose there is a ufunc with two inputs, A and B. Suppose A has shape 4 x 6 x 5 while B is a length 5 array. Due to the 1st rule, B will be interpreted as a 1 x 1 x 5 array, and then because of the second rule B will be interpreted as a 4 x 6 x 5 array by repeating the elements of B in the obvious way.
due to the first rule of broadcasting, 1s are typically pre-pended to the shapes of smaller arrays, but often we would rather add 1s to the ends of the shapes of smaller arrays; given an array B, how could we return an array with 2 additional 1s appended to B's shape?	>>> B = np.arange(5)<br>>>> B.shape # (5, )<br>>>> B_ext = B[..., np.newaxis, np.newaxis]<br>>>> B_ext.shape # (5, 1, 1)
an important aspect of broadcasting is the calculation of functions on regularly spaced grids; suppose you wish to show a portion of the multiplication table by computing the function a * b on a grid with a running from 6 to 9, and b running from 12 to 16; how could you demonstrate this in code with ufuncs and broadcasting?	>>> a = np.arange(6, 10)<br>array([6, 7, 8, 9])<br>>>> b = np.arange(12, 17)<br>array([12, 13, 14, 15, 16])<br>>>> table = a[:, np.newaxis] * b<br>array([[ 72,  78,  84,  90,  96],<br>       [ 84,  91,  98, 105, 112],<br>       [ 96, 104, 112, 120, 128],<br>       [108, 117, 126, 135, 144]])
explicit looping of numpy arrays using general Python iteration instead of optimized ufuncs can often be how much slower?	around two orders of magnitude slower (but if Cython or Numba is used to compile the loop into machine code, iteration over ndarrays can be comparable in speed to using ufuncs)
consider an ndarray defined as:<br><br>d3 = np.arange(30).reshape(2,3,5)<br><br>where you wanted to add 10 to all elements of d3[1, ...] but avoid adding elements to d3[0, ...]; typically, explicit Python looping over the first dimension of a high-dimension array may cause little performance effect, so how could you operate differently on each slice of d3 with enumerate?	>>> for n, x in enumerate(d3):<br>...         x += n * 10<br>>>> d3<br>array([[[ 0,  1,  2,  3,  4],<br>        [ 5,  6,  7,  8,  9],<br>        [10, 11, 12, 13, 14]],<br><br>       [[25, 26, 27, 28, 29],<br>        [30, 31, 32, 33, 34],<br>        [35, 36, 37, 38, 39]]])
how would you visit all elements of an array arr in a systematic, element-wise fashion with numpy's iterator? if using numpy's iterator, would the order traversal of arr and arr.T differ?	for x in np.nditer(arr):<br>    ...<br><br>Iteration with nditer is performed according to memory layout of the array rather than C / Fortran ordering, for access efficiency, assuming the loop simply wants to visit every element (order be damned!); thus they would be traversed in the same order, though this can be altered with parameters.<br>
if given two arrays, <br><br>a = np.arange(3)<br>b = np.arange(10,16).reshape(2,3)<br><br>and iteration via<br><br>for x, y in np.nditer([a,b]):<br>    print x, y<br><br>what is the expected output? why would this not work without the reshaping function?	0 10<br>1 11<br>2 12<br>0 13<br>1 14<br>2 15<br><br>without the reshaping function, you would have arrays of shape (3, ) and shape (6, ), which cannot be broadcast together, whereas with reshaping these arrays can be iterated together
